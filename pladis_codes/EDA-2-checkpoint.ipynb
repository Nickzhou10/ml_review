{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import researchpy as rp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from itertools import chain\n",
    "# visualization\n",
    "from pandas.plotting import scatter_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "#plotly\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode, plot, iplot\n",
    "import plotly as py \n",
    "import plotly.graph_objs as go # plotly graphical object\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "# setting the general visualization style\n",
    "sns.set_style('whitegrid')\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "# ignoring warnings in the notebook\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "# To display full output \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/project/data_for_models/feature_eng3_final.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['promo_adjusted_excess_return'] = df[\"Excess_sales_sub\"]/(df[\"Promo_depth\"]+1)\n",
    "plot1 = df.groupby(['Cum.promo.total','full_name','channel'\n",
    "                        ], as_index=False)[\"promo_adjusted_excess_return\"].mean()\n",
    "\n",
    "plot1 = plot1.pivot_table(index=[\"Cum.promo.total\"], \n",
    "                                 columns=['full_name','channel'], \n",
    "                                 values=['promo_adjusted_excess_return']).reset_index()\n",
    "plot1 = plot1['promo_adjusted_excess_return']\n",
    "plot2 = plot1.cumsum()\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(plot1.to_html()))\n",
    "display(HTML(plot2.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/project/data_for_models/feature_eng3_final.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/project/data_for_models/feature_eng3_final.csv\",index_col=0)\n",
    "df['promo_adjusted_excess_return'] = df[\"Excess_sales_sub\"]/(df[\"Promo_depth\"]+1)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['quarter'] = pd.PeriodIndex(df.date, freq='Q')\n",
    "df = df.drop(df.loc[df.quarter=='2018Q2'].index)\n",
    "df = df.groupby(['quarter','full_name','channel','Subsegment'\n",
    "                        ], as_index=False)[\"promo\",'promo_adjusted_excess_return'].sum()\n",
    "#promo = df.groupby(['quarter','full_name','channel','Subsegment'\n",
    "#                        ], as_index=False)[\"\"].sum()\n",
    "df['promo_adjusted_excess_return_log'] = (df['promo_adjusted_excess_return'])\n",
    "target = df['promo_adjusted_excess_return_log']\n",
    "target.to_excel(\"/project/data_for_models/target.xlsx\", sheet_name='Sheet1')\n",
    "cat_var_to_enc = ['quarter']\n",
    "for var in cat_var_to_enc:\n",
    "    df = pd.concat([df,\\\n",
    "                          pd.get_dummies(df[var],\\\n",
    "                                         prefix=var, prefix_sep='_', drop_first=False)], axis=1)\n",
    "df = df.drop(['full_name','promo_adjusted_excess_return','quarter','channel','Subsegment','promo_adjusted_excess_return_log'],axis=1)\n",
    "#df['q1'] = df['quarter_2019Q1']+df['quarter_2020Q1']+df['quarter_2021Q1']\n",
    "#df['q2'] = df['quarter_2019Q2']+df['quarter_2020Q2']+df['quarter_2021Q2']\n",
    "#df['q3'] = df['quarter_2018Q3']+df['quarter_2019Q3']+df['quarter_2020Q3']\n",
    "#df['q4'] = df['quarter_2018Q4']+df['quarter_2019Q4']+df['quarter_2020Q4']\n",
    "\n",
    "#df = df[['q2','q3','q4','promo','channel_Sainsbury excl Local','channel_Tesco Express',\n",
    "#    'channel_Tesco excl. Express','Subsegment_EDB','Subsegment_EDT','Subsegment_Healthier']]\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = sm.OLS(target,df)\n",
    "results_ols = model1.fit()\n",
    "\n",
    "print(results_ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/project/data_for_models/feature_eng3_final.csv\",index_col=0)\n",
    "df['promo_adjusted_excess_return'] = df[\"Excess_sales_sub\"]/(df[\"Promo_depth\"]+1)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['quarter'] = pd.PeriodIndex(df.date, freq='Q')\n",
    "df = df.drop(df.loc[df.quarter=='2018Q2'].index)\n",
    "df = df.groupby(['quarter','full_name','channel','Subsegment'\n",
    "                        ], as_index=False)[\"promo\",'promo_adjusted_excess_return'].sum()\n",
    "#promo = df.groupby(['quarter','full_name','channel','Subsegment'\n",
    "#                        ], as_index=False)[\"\"].sum()\n",
    "df['promo_adjusted_excess_return_log'] = (df['promo_adjusted_excess_return'])\n",
    "target = df['promo_adjusted_excess_return_log']\n",
    "target.to_excel(\"/project/data_for_models/target.xlsx\", sheet_name='Sheet1')\n",
    "cat_var_to_enc = ['quarter']\n",
    "for var in cat_var_to_enc:\n",
    "    df = pd.concat([df,\\\n",
    "                          pd.get_dummies(df[var],\\\n",
    "                                         prefix=var, prefix_sep='_', drop_first=False)], axis=1)\n",
    "df = df.drop(['full_name','promo_adjusted_excess_return','quarter'],axis=1)\n",
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "channel = df['channel'].drop_duplicates().values.tolist()\n",
    "Subsegment = df['Subsegment'].drop_duplicates().values.tolist()\n",
    "df_solution1 = df\n",
    "channels = []\n",
    "r2 = []\n",
    "Subsegments = []\n",
    "promo_freq_efficiency = []\n",
    "promo_adjusted_excess_return_log = []\n",
    "for i in Subsegment:\n",
    "    for j in channel:\n",
    "        reg = LinearRegression()\n",
    "        y= df_solution1.loc[(df_solution1.Subsegment == i)&\n",
    "                            (df_solution1.channel== j),'promo_adjusted_excess_return_log'].values.reshape(-1, 1)\n",
    "        x = df_solution1.loc[(df_solution1.Subsegment == i)&\n",
    "                            (df_solution1.channel== j),'promo'].values.reshape(-1, 1)\n",
    "        reg.fit(x,y)\n",
    "        r_sq = reg.score(x, y)\n",
    "        Subsegments.append(df_solution1.loc[df_solution1['Subsegment'] == i]['Subsegment'].drop_duplicates().values.tolist())\n",
    "        channels.append(df_solution1.loc[df_solution1['channel'] == j]['channel'].drop_duplicates().values.tolist())\n",
    "        ceo = abs(reg.coef_[0])\n",
    "        promo_freq_efficiency.append(ceo)\n",
    "        r2.append(r_sq)\n",
    "        promo_adjusted_excess_return_log.append(df_solution1.loc[(df_solution1.Subsegment == i)&\n",
    "                            (df_solution1.channel== j),'promo_adjusted_excess_return_log'].mean())\n",
    "        \n",
    "Subsegments = list(chain.from_iterable(Subsegments))\n",
    "channels = list(chain.from_iterable(channels))\n",
    "data = {'Subsegment':Subsegments, \"channel\":channels,\"promo_freq_efficiency\": promo_freq_efficiency}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = pd.DataFrame(data)\n",
    "df_freq['promo_freq_efficiency'] = df_freq['promo_freq_efficiency'].str[0]\n",
    "df_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
