{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from itertools import chain\n",
    "# visualization\n",
    "from pandas.plotting import scatter_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pprint import pprint\n",
    "import pandas_profiling as pp\n",
    "%matplotlib inline\n",
    "#plotly\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode, plot, iplot\n",
    "import plotly as py \n",
    "import plotly.graph_objs as go # plotly graphical object\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "# setting the general visualization style\n",
    "sns.set_style('whitegrid')\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Libraries for Statistical Models\n",
    "import statsmodels.api as sm\n",
    "# ignoring warnings in the notebook\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "# To display full output \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(name):\n",
    "    ax = sns.lineplot(x=df_sku[df_sku['full_name'] == name]['date'],\n",
    "                     y=df_sku[df_sku['full_name'] == name]['price_per_unit'],\n",
    "                     hue=df_sku[df_sku['full_name'] == name]['channel'])\n",
    "    #plt.figure(figsize=[20, 10]) # Set dimensions for figure\n",
    "    ax.set_title(name) #set title;\n",
    "    plt.show();\n",
    "#for i in df_valid['full_name'].values.tolist():\n",
    "#    plot(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotly(name, mode):\n",
    "    if mode == 1:\n",
    "        fig = px.line(df_sku[df_sku['full_name']== name],\n",
    "                  x='date', y='price_per_unit', title='Price_per_units for '+ name,\n",
    "                  color='channel', template=\"none\")\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "        fig.show();\n",
    "        fig = px.line(df_sku[df_sku['full_name']==name],\n",
    "                      x='date', y='Sales', title='Sales for '+ name,\n",
    "                      color='channel', template=\"none\")\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "        fig.show();\n",
    "\n",
    "        fig = px.line(df_sku[df_sku['full_name']==name],\n",
    "                      x='date', y='distribution', title='distribution for '+ name,\n",
    "                      color='channel', template=\"none\")\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "        fig.show();\n",
    "    else:\n",
    "        fig = px.line(df_sku[df_sku['full_name']== name],\n",
    "              x='date', y='price_per_unit', title='Price_per_units for '+ name,\n",
    "              color='channel', template=\"none\")\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "        fig.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sku_raw1 = pd.read_csv(\"/project/raw_data/SKU.csv\",index_col=0)\n",
    "df_sku_raw2 = pd.read_csv(\"/project/raw_data/SKU2.csv\",index_col=0)\n",
    "# rename rows\n",
    "df_sku_raw1.loc[df_sku_raw1['biscuit_category'] == 1, ['biscuit_category']] = 'EVERYDAY TREATS'\n",
    "df_sku_raw1.loc[df_sku_raw1['biscuit_category'] == 2, ['biscuit_category']] = 'EVERYDAY BISCUITS'\n",
    "df_sku_raw1.loc[df_sku_raw1['biscuit_category'] == 3, ['biscuit_category']] = 'CHOCOLATE BISCUIT BARS'\n",
    "# merge two dfs\n",
    "df_sku_raw = pd.merge(df_sku_raw1, df_sku_raw2, how=\"outer\")\n",
    "df_sku_raw = df_sku_raw.drop(columns=['sheet'])\n",
    "df_sku_raw = df_sku_raw.loc[(df_sku_raw.date < '2021-05-22')]\n",
    "df_sku_raw = df_sku_raw.loc[(df_sku_raw.date >= '2018-05-22')]\n",
    "# fix 0 and less than 0 data\n",
    "df_sku_raw[df_sku_raw['Sales'] <= 0]['Sales'] = 0\n",
    "df_sku_raw[df_sku_raw['units_sold'] <= 0]['units_sold'] = 0\n",
    "df_sku_raw[df_sku_raw['kg_sold'] <= 0]['kg_sold'] = 0\n",
    "# reshaping the levels\n",
    "df_sku_raw = df_sku_raw[df_sku_raw['channel'].isin(['Tesco Express','Tesco excl. Express','Sainsbury Local','Sainsbury excl Local'])]\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Tesco Express'),'retailer']='Tesco'\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Tesco excl. Express'),'retailer']='Tesco'\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Sainsbury Local'),'retailer']='Sainsbury'\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Sainsbury excl Local'),'retailer']='Sainsbury'\n",
    "# applying date dtype\n",
    "df_sku_raw['date'] = pd.to_datetime(df_sku_raw['date'])\n",
    "df_sku_raw['WeekOfYear'] = df_sku_raw.date.dt.weekofyear\n",
    "df_sku_raw['Year'] = df_sku_raw.date.dt.year\n",
    "df_sku_raw['Month'] = df_sku_raw.date.dt.month\n",
    "# renaming features\n",
    "df_sku_raw.loc[(df_sku_raw['biscuit_category'] == 'HEALTHIER BISCUITS'),'biscuit_category']='Healthier'\n",
    "df_sku_raw.loc[(df_sku_raw['biscuit_category'] == 'CHOCOLATE BISCUIT BARS'),'biscuit_category']='CBB'\n",
    "df_sku_raw.loc[(df_sku_raw['biscuit_category'] == 'EVERYDAY TREATS'),'biscuit_category']='EDT'\n",
    "df_sku_raw.loc[(df_sku_raw['biscuit_category'] == 'EVERYDAY BISCUITS'),'biscuit_category']='EDB'\n",
    "df_sku_raw.rename(columns={'biscuit_category':'Subsegment'}, inplace=True)\n",
    "# re-leveling\n",
    "df_sku_raw = df_sku_raw[~df_sku_raw['channel'].isin(['Tesco','Sainsbury'])]\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Tesco Express'),'format']='Express'\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Tesco excl. Express'),'format']='Main'\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Sainsbury Local'),'format']='Express'\n",
    "df_sku_raw.loc[(df_sku_raw.channel == 'Sainsbury excl Local'),'format']='Main'\n",
    "# drop useless variabel\n",
    "df_sku_raw = df_sku_raw.drop(['off_shelf'], axis=1)\n",
    "\n",
    "# preview\n",
    "df_sku_raw\n",
    "df_sku_raw.info()\n",
    "df_sku_raw.describe()\n",
    "df_sku_raw.to_csv(\"/project/data_cleaning/SKU_new.csv\")  \n",
    "df_sku = df_sku_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import researchpy as rp\n",
    "rp.summary_cat(df_sku[['biscuit_category']])\n",
    "rp.summary_cat(df_sku[['pack_type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Threshold = 0\n",
    "df_sku_gb = df_sku.groupby(['full_name'],as_index=False,sort=False).sum()\n",
    "Tesco_Express = []\n",
    "Tesco_Main = []\n",
    "Sainsbury_Local = []\n",
    "Sainsbury_Main = []\n",
    "product = df_sku['full_name'].drop_duplicates().values.tolist()\n",
    "company = []\n",
    "total_sales = df_sku_gb['Sales'].values.tolist()\n",
    "brand = []\n",
    "pack = []\n",
    "for i in product:\n",
    "    Tesco_Express.append(df_sku[(df_sku['full_name']== i) \n",
    "                                & (df_sku['distribution']>Threshold)\n",
    "                                & (df_sku['channel']=='Tesco Express')]['date'].count())\n",
    "    Tesco_Main.append(df_sku[(df_sku['full_name']== i) \n",
    "                                & (df_sku['distribution']>Threshold)\n",
    "                                & (df_sku['channel']=='Tesco excl. Express')]['date'].count())\n",
    "    Sainsbury_Local.append(df_sku[(df_sku['full_name']== i) \n",
    "                                & (df_sku['distribution']>Threshold)\n",
    "                                & (df_sku['channel']=='Sainsbury Local')]['date'].count())\n",
    "    Sainsbury_Main.append(df_sku[(df_sku['full_name']== i) \n",
    "                                & (df_sku['distribution']>Threshold)\n",
    "                                & (df_sku['channel']=='Sainsbury excl Local')]['date'].count())\n",
    "\n",
    "    company.append(df_sku.loc[df_sku['full_name'] == i]['company']\n",
    "                    .drop_duplicates().values.tolist())\n",
    "    brand.append(df_sku.loc[df_sku['full_name'] == i]['brand']\n",
    "                    .drop_duplicates().values.tolist())\n",
    "    pack.append(df_sku.loc[df_sku['full_name'] == i]['pack_type']\n",
    "                    .drop_duplicates().values.tolist())\n",
    "company = list(chain.from_iterable(company))\n",
    "brand = list(chain.from_iterable(brand))\n",
    "pack = list(chain.from_iterable(pack))\n",
    "data = {'full_name':product, \"Tesco_Express\":Tesco_Express,\"Tesco_Main\": Tesco_Main,\n",
    "        'Sainsbury_Local':Sainsbury_Local,'Sainsbury_Main':Sainsbury_Main,\n",
    "       'total_sales':total_sales,'company':company,'brand':brand, 'pack':pack}\n",
    "df_flt = pd.DataFrame(data)\n",
    "df_flt = df_flt.sort_values(by=['total_sales'], ascending=False)\n",
    "\n",
    "fuse1=0\n",
    "fuse2=0\n",
    "df_valid = df_flt[df_flt['Tesco_Express']>=fuse1]\n",
    "df_valid = df_valid[df_flt['Tesco_Main']>=fuse1]\n",
    "df_valid = df_valid[df_flt['Sainsbury_Local']>=fuse2]\n",
    "df_valid = df_valid[df_flt['Sainsbury_Main']>=fuse2]\n",
    "df_valid\n",
    "#df_valid.to_csv(\"/project/data_cleaning/df_without_missing.csv\")  \n",
    "#df_valid.to_html(\"/project/data_cleaning/df_valid.html\") \n",
    "df_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select skus that has missing values\n",
    "df_problematic = df_valid[df_valid['Tesco_Express']!=156]\n",
    "# drop skus that cannot be imputated\n",
    "drop = [36,223,154,141,152,187,15,237,7,16]\n",
    "df_problematic = df_problematic.drop(index=drop)\n",
    "#df_problematic.describe()\n",
    "df_not_bad = df_problematic.drop(df_problematic[(df_problematic['Sainsbury_Local']==0)].index)\n",
    "df_not_bad = df_not_bad.drop(df_not_bad[(df_not_bad['Sainsbury_Main']==0)].index)\n",
    "df_not_bad = df_not_bad.drop(index=[37,10])\n",
    "df_not_bad\n",
    "df_not_bad.to_csv(\"/project/data_cleaning/df_to_be_imputed.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SKU_new = pd.read_csv(\"/project/data_cleaning/SKU_new.csv\",index_col=0)\n",
    "#df_valid = pd.read_csv(\"/project/data_cleaning/df_valid.csv\",index_col=0)\n",
    "df_valid = SKU_new[SKU_new['full_name'].isin(df_valid['full_name'].values.tolist())]\n",
    "df_valid = df_valid[~df_valid['channel'].isin(['Tesco','Sainsbury'])]\n",
    "df_valid.loc[(df_valid.channel == 'Tesco Express'),'format']='Express'\n",
    "df_valid.loc[(df_valid.channel == 'Tesco excl. Express'),'format']='Main'\n",
    "df_valid.loc[(df_valid.channel == 'Sainsbury Local'),'format']='Express'\n",
    "df_valid.loc[(df_valid.channel == 'Sainsbury excl Local'),'format']='Main'\n",
    "df_valid.loc[(df_valid.date >= '2020-01-31'),'covid']='Yes'\n",
    "df_valid.loc[(df_valid.date < '2020-01-31'),'covid']='No'\n",
    "#df_reg.drop(['weight','off_shelf','units_sold','kg_sold'],axis=1)\n",
    "#df_valid.to_csv(\"/project/data_cleaning/df_reg.csv\") \n",
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df_valid\n",
    "df_eda['date'] = pd.to_datetime(df_eda['date'])\n",
    "df_eda.loc[(df_eda['biscuit_category'] == 'HEALTHIER BISCUITS'),'biscuit_category']='Healthier'\n",
    "df_eda.loc[(df_eda['biscuit_category'] == 'CHOCOLATE BISCUIT BARS'),'biscuit_category']='CBB'\n",
    "df_eda.loc[(df_eda['biscuit_category'] == 'EVERYDAY TREATS'),'biscuit_category']='EDT'\n",
    "df_eda.loc[(df_eda['biscuit_category'] == 'EVERYDAY BISCUITS'),'biscuit_category']='EDB'\n",
    "df_eda.rename(columns={'biscuit_category':'category'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.ProfileReport(df_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorplot(x,y,colour,size):\n",
    "    order = (df_eda[(df_eda['Year']==2021)]\n",
    "             .groupby(y)[x]\n",
    "             .mean()\n",
    "             .sort_values()\n",
    "             .index\n",
    "    )\n",
    "    # setting up the factor plot\n",
    "    figure6=sns.factorplot(x,y,data=df_eda,\n",
    "                       hue='Year',\n",
    "                       size=size,\n",
    "                       aspect=0.6,\n",
    "                       palette=colour,\n",
    "                       order=order,\n",
    "                       join=False,\n",
    "                       col=\"format\"\n",
    "    )\n",
    "    # labeling\n",
    "    plt.title('Factor plot for average '+x+' by '+y +' and year', fontsize =15)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "factorplot('price_per_unit','full_name','OrRd',12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "factorplot('Sales','full_name','OrRd',12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotly('BSCTS DGSTV MCVTS DGSTVS PLN 400 GM SNGL',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorplot('price_per_unit','brand','OrRd',12)\n",
    "#lotus biscoff vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorplot('Sales','brand','OrRd',12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "df_sweetb = pd.read_csv(\"/project/raw_data/Sweet_Biscuits.csv\",index_col=0)\n",
    "# applying date dtype\n",
    "df_sweetb['date'] = pd.to_datetime(df_sweetb['date'])\n",
    "df_sweetb = df_sweetb.drop(['sheet_number'], axis=1)\n",
    "df_ts = df_sweetb.set_index('date')\n",
    "df_ts1 = df_ts[df_ts['channel'] == 'Tesco Express']['Sales']\n",
    "df_ts2 = df_ts[df_ts['channel'] == 'Tesco excl. Express']['Sales']\n",
    "df_ts3 = df_ts[df_ts['channel'] == 'Sainsbury Local']['Sales']\n",
    "df_ts4 = df_ts[df_ts['channel'] == 'Sainsbury excl Local']['Sales']\n",
    "def plot_seasonal_dec(df,period,name,color):\n",
    "    res = seasonal_decompose(df, model = \"additive\", period = period)\n",
    "    fig, axes = plt.subplots(4,1, figsize=(15,7), sharex=True)\n",
    "    axes[0].set_title(name + 'seasonal decompose analysis for sweet biscuits sales performace', size =15)\n",
    "    res.observed.plot(ax=axes[0], legend=False, color = color)\n",
    "    axes[0].set_ylabel('observed', size=15)\n",
    "    res.trend.plot(ax=axes[1], legend=False, color = color)\n",
    "    axes[1].set_ylabel('trend', size=15)\n",
    "    res.seasonal.plot(ax=axes[2], legend=False, color = color)\n",
    "    axes[2].set_ylabel('seasoanlity', size=15)\n",
    "    res.resid.plot(ax=axes[3], legend=False, color = color)\n",
    "    axes[3].set_ylabel('residual', size=15)\n",
    "    plt.show();\n",
    "for i in [52]:\n",
    "    plot_seasonal_dec(df_ts1,i,'Tesco express ','dodgerblue')\n",
    "    plot_seasonal_dec(df_ts2,i,'Tesco excl. Express ','dodgerblue')\n",
    "    plot_seasonal_dec(df_ts3,i,'Sainsbury Local ','orangered')\n",
    "    plot_seasonal_dec(df_ts4,i,'Sainsbury excl Local ','orangered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. prices in segment/competitor/format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda1 = df_eda\n",
    "df_eda1.loc[(~df_eda1['company'].isin(['PLADIS UK','MONDELEZ INTERNATIONAL',\n",
    "                                'NESTLE ROWNTREE','GENERAL MILLS',\n",
    "                                'BURTONS BISCUITS','PRIVATE LABEL'])),'company'] ='Others'\n",
    "df_eda1.groupby(\"company\")['Sales'].sum().sort_values()\n",
    "df_eda2 = df_eda\n",
    "df_eda2.loc[(~df_eda2['brand'].isin(['KIT KAT','MCVITIES DIGESTIVES',\n",
    "                                'CADBURY BRUNCH BAR','OREO COOKIES',\n",
    "                               'MCVITIES RICH TEA','NATURE VALLEY CRUNCHY BARS',\n",
    "                                    'MARYLAND COOKIES','PRIVATE LABEL'])),'brand'] ='Others'\n",
    "df_eda.groupby(\"brand\")['Sales'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = df_eda1.groupby([\"format\", \"company\",'category',\"retailer\"], as_index=False)[\"price_per_unit\"].mean()\n",
    "plot2 = df_eda1.groupby([\"format\", \"company\",'category',\"retailer\"], as_index=False)[\"Sales\"].sum()\n",
    "plot3 = df_eda2.groupby([\"format\", \"brand\",'category',\"retailer\"], as_index=False)[\"price_per_unit\"].mean()\n",
    "plot4 = df_eda2.groupby([\"format\", \"brand\",'category',\"retailer\"], as_index=False)[\"Sales\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(plot1, x=\"format\", y=\"price_per_unit\", color=\"company\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"category\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"category\": [\"Healthier\", \"CBB\",'EDT','EDB']},\n",
    "             title='Average Price for each segment, format, company, and retailer')\n",
    "fig.show();\n",
    "\n",
    "fig = px.bar(plot2, x=\"format\", y=\"Sales\", color=\"company\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"category\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"category\": [\"Healthier\", \"CBB\",'EDT','EDB']},\n",
    "            title='Sales for each segment, format, company, and retailer')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(plot3, x=\"format\", y=\"price_per_unit\", color=\"brand\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"category\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"category\": [\"Healthier\", \"CBB\",'EDT','EDB']},\n",
    "             title='Average Price for each segment, format, brand, and retailer')\n",
    "fig.show();\n",
    "\n",
    "fig = px.bar(plot4, x=\"format\", y=\"Sales\", color=\"brand\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"category\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"category\": [\"Healthier\", \"CBB\",'EDT','EDB']},\n",
    "            title='Sales for each segment, format, brand, and retailer')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task5 = pd.read_csv(\"/project/task5.csv\",index_col=0)\n",
    "task5.loc[(task5['biscuit_category'] == 'HEALTHIER BISCUITS'),'biscuit_category']='Healthier'\n",
    "task5.loc[(task5['biscuit_category'] == 'CHOCOLATE BISCUIT BARS'),'biscuit_category']='CBB'\n",
    "task5.loc[(task5['biscuit_category'] == 'EVERYDAY TREATS'),'biscuit_category']='EDT'\n",
    "task5.loc[(task5['biscuit_category'] == 'EVERYDAY BISCUITS'),'biscuit_category']='EDB'\n",
    "task5.rename(columns={'biscuit_category':'category'}, inplace=True)\n",
    "plot3 = task5.groupby(['full_name',\"format\", \"company\",\"retailer\",'category'], as_index=False)[\"promo\",'Sales'].sum()\n",
    "\n",
    "plot3 = plot3[plot3['company'].isin(['PLADIS UK','MONDELEZ INTERNATIONAL',\n",
    "                                'NESTLE ROWNTREE','GENERAL MILLS',\n",
    "                                'BURTONS BISCUITS','PRIVATE LABEL'])]\n",
    "plot3 = plot3.groupby([\"format\", \"company\",\"retailer\",'category'], as_index=False)[\"promo\",'Sales'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(plot3, x=\"format\", y=\"promo\", color=\"company\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"category\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"category\": [\"Healthier\", \"CBB\",'EDT','EDB']},\n",
    "             title='Average number of weeks in promotion for each year, format, company, and retailer')\n",
    "fig.show();\n",
    "\n",
    "fig = px.bar(plot3, x=\"format\", y=\"Sales\", color=\"company\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"category\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"category\": [\"Healthier\", \"CBB\",'EDT','EDB']},\n",
    "             title='Average number of weeks in promotion by segments, formats, company, and retailer')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.bar(plot3, x=\"format\", y=\"promo\", color=\"company\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"Year\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"Year\": [\"2018\", \"2019\",'2020','2021']},\n",
    "             title='Average number of weeks in promotion for each year, format, company, and retailer')\n",
    "fig.show();\n",
    "\n",
    "fig = px.bar(plot3, x=\"format\", y=\"Sales\", color=\"company\", barmode=\"group\",\n",
    "             facet_row=\"retailer\", facet_col=\"Year\", template=\"none\",\n",
    "             category_orders={\"retailer\": [\"Tesco\", \"Sainsbury\"],\n",
    "                             \"Year\": [\"2018\", \"2019\",'2020','2021']},\n",
    "             title='Average number of weeks in promotion for each year, format, company, and retailer')\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation of missing/strange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df_sku_raw[df_sku_raw['full_name'].isin(df_valid['full_name'].values.tolist())]\n",
    "df = df[~df['channel'].isin(['Tesco','Sainsbury'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['had_promo']=1\n",
    "df_valid.loc[(df_valid['full_name'].isin(['BSCTS DGSTV MCVTS DGSTVS PLN 400 GM SNGL',\n",
    "                                                     'BSCTS RCH T MCVTS RCH T PLN 300 GM SNGL',\n",
    "                                                     'BSCTS MLTD PRVT LBL MLTD MLK 200 GM SNGL',\n",
    "                                                     'BSCTS FG RLLS PRVT LBL FG 200 GM SNGL']) == True),'had_promo']=0\n",
    "df_valid = df_valid.drop(df_valid[df_valid.units_sold < 100].index)\n",
    "\n",
    "df_valid = df_valid[~df_valid['full_name'].isin(['BSCTS DGSTV MCVTS DGSTVS PLN 400 GM SNGL',\n",
    "                                                     'BSCTS RCH T MCVTS RCH T PLN 300 GM SNGL',\n",
    "                                                     'BSCTS MLTD PRVT LBL MLTD MLK 200 GM SNGL',\n",
    "                                                     'BSCTS FG RLLS PRVT LBL FG 200 GM SNGL'])]\n",
    "\n",
    "df_valid_reg = df_valid\n",
    "df_valid_reg.to_csv(\"/project/data_cleaning/df_valid_reg.csv\") \n",
    "df_valid_reg.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
